{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7d65aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors, kneighbors_graph\n",
    "from sklearn.manifold import trustworthiness\n",
    "from scipy.sparse.csgraph import dijkstra\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.manifold import MDS\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "from tqdm.auto import tqdm\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import queue\n",
    "import json\n",
    "\t\t\n",
    "\n",
    "# Antenna definitions\n",
    "ASSIGNMENTS = [\n",
    "\t[0, 13, 31, 29, 3, 7, 1, 12 ],\n",
    "\t[30, 26, 21, 25, 24, 8, 22, 15],\n",
    "\t[28, 5, 10, 14, 6, 2, 16, 18],\n",
    "\t[19, 4, 23, 17, 20, 11, 9, 27]\n",
    "]\n",
    "\n",
    "ANTENNACOUNT = np.sum([len(antennaArray) for antennaArray in ASSIGNMENTS])\n",
    "\n",
    "def load_calibrate_timedomain(path, offset_path):\n",
    "\toffsets = None\n",
    "\twith open(offset_path, \"r\") as offsetfile:\n",
    "\t\toffsets = json.load(offsetfile)\n",
    "\t\n",
    "\tdef record_parse_function(proto):\n",
    "\t\trecord = tf.io.parse_single_example(\n",
    "\t\t\tproto,\n",
    "\t\t\t{\n",
    "\t\t\t\t\"csi\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "\t\t\t\t\"pos-tachy\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "\t\t\t\t\"time\": tf.io.FixedLenFeature([], tf.float32, default_value=0),\n",
    "\t\t\t},\n",
    "\t\t)\n",
    "\n",
    "\t\tcsi = tf.ensure_shape(tf.io.parse_tensor(record[\"csi\"], out_type=tf.float32), (ANTENNACOUNT, 1024, 2))\n",
    "\t\tcsi = tf.complex(csi[:, :, 0], csi[:, :, 1])\n",
    "\t\tcsi = tf.signal.fftshift(csi, axes=1)\n",
    "\n",
    "\t\tposition = tf.ensure_shape(tf.io.parse_tensor(record[\"pos-tachy\"], out_type=tf.float64), (3))\n",
    "\t\ttime = tf.ensure_shape(record[\"time\"], ())\n",
    "\n",
    "\t\treturn csi, position[:2], time\n",
    "\n",
    "\tdef apply_calibration(csi, pos, time):\n",
    "\t\tsto_offset = tf.tensordot(tf.constant(offsets[\"sto\"]), 2 * np.pi * tf.range(tf.shape(csi)[1], dtype = np.float32) / tf.cast(tf.shape(csi)[1], np.float32), axes = 0)\n",
    "\t\tcpo_offset = tf.tensordot(tf.constant(offsets[\"cpo\"]), tf.ones(tf.shape(csi)[1], dtype = np.float32), axes = 0)\n",
    "\t\tcsi = tf.multiply(csi, tf.exp(tf.complex(0.0, sto_offset + cpo_offset)))\n",
    "\n",
    "\t\treturn csi, pos, time\n",
    "\n",
    "\tdef csi_time_domain(csi, pos, time):\n",
    "\t\tcsi = tf.signal.fftshift(tf.signal.ifft(tf.signal.fftshift(csi, axes=1)),axes=1)\n",
    "\n",
    "\t\treturn csi, pos, time\n",
    "\n",
    "\tdef cut_out_taps(tap_start, tap_stop):\n",
    "\t\tdef cut_out_taps_func(csi, pos, time):\n",
    "\t\t\treturn csi[:,tap_start:tap_stop], pos, time\n",
    "\n",
    "\t\treturn cut_out_taps_func\n",
    "\n",
    "\tdef order_by_antenna_assignments(csi, pos, time):\n",
    "\t\tcsi = tf.stack([tf.gather(csi, antenna_inidces) for antenna_inidces in ASSIGNMENTS])\n",
    "\t\treturn csi, pos, time\n",
    "\t\n",
    "\tdataset = tf.data.TFRecordDataset(path)\n",
    "\t\n",
    "\tdataset = dataset.map(record_parse_function, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "\tdataset = dataset.map(apply_calibration, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "\tdataset = dataset.map(csi_time_domain, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "\tdataset = dataset.map(cut_out_taps(507, 520), num_parallel_calls = tf.data.AUTOTUNE)\n",
    "\tdataset = dataset.map(order_by_antenna_assignments, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "\n",
    "\treturn dataset\n",
    "\n",
    "inputpaths = [\n",
    "\t{\n",
    "\t\t\"tfrecords\" : \"dichasus/dichasus-cf02.tfrecords\",\n",
    "\t\t\"offsets\" : \"dichasus/reftx-offsets-dichasus-cf02.json\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"tfrecords\" : \"dichasus/dichasus-cf03.tfrecords\",\n",
    "\t\t\"offsets\" : \"dichasus/reftx-offsets-dichasus-cf03.json\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"tfrecords\" : \"dichasus/dichasus-cf04.tfrecords\",\n",
    "\t\t\"offsets\" : \"dichasus/reftx-offsets-dichasus-cf04.json\"\n",
    "\t}\n",
    "]\n",
    "\n",
    "full_dataset = load_calibrate_timedomain(inputpaths[0][\"tfrecords\"], inputpaths[0][\"offsets\"])\n",
    "\n",
    "for path in inputpaths[1:]:\n",
    "\tfull_dataset = full_dataset.concatenate(load_calibrate_timedomain(path[\"tfrecords\"], path[\"offsets\"]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410bda64",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = full_dataset.enumerate().filter(lambda idx, value : (idx % 4 == 0))\n",
    "training_set = training_set.map(lambda idx, value : value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e82d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruth_positions = []\n",
    "csi_time_domain = []\n",
    "timestamps = []\n",
    "for csi, pos, time in training_set.batch(1000):\n",
    "\tcsi_time_domain.append(csi.numpy())\n",
    "\tgroundtruth_positions.append(pos.numpy())\n",
    "\ttimestamps.append(time.numpy())\n",
    "\n",
    "csi_time_domain = np.concatenate(csi_time_domain)\n",
    "groundtruth_positions = np.concatenate(groundtruth_positions)\n",
    "timestamps = np.concatenate(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f12a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "zip_path = \"siamese_final_model.zip\"  # Update with your actual path\n",
    "extract_path = \"siamese_model_extracted\"\n",
    "\n",
    "# Extract ZIP\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "print(\"Extraction complete. Files are inside:\", extract_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce6699f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Correct path to your SavedModel directory\n",
    "model_path = os.path.join(\"siamese_model_extracted\", \"siamese_final_model\")\n",
    "\n",
    "# Custom Keras Layer to Load a SavedModel\n",
    "class CustomTFSMLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, model_path, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.model = tf.saved_model.load(model_path)  # Load SavedModel\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Ensure inputs is a tuple with two tensors: input_1 and input_2\n",
    "        input_1, input_2 = inputs\n",
    "        \n",
    "        # Pass inputs as a dictionary matching the model signature\n",
    "        inference_fn = self.model.signatures[\"serving_default\"]\n",
    "        \n",
    "        # Pass the actual tensors (input_1 and input_2) to the inference function\n",
    "        return inference_fn(input_1=input_1, input_2=input_2)[\"concatenate\"]\n",
    "\n",
    "# Instantiate the model layer\n",
    "model_layer = CustomTFSMLayer(model_path)\n",
    "\n",
    "print(\"Model Loaded Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99aeaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def build_denoising_autoencoder(input_dim):\n",
    "    \"\"\"\n",
    "    Builds a denoising autoencoder model.\n",
    "    \n",
    "    Args:\n",
    "        input_dim: Dimension of the input features (e.g., 832 for features_F1).\n",
    "    \n",
    "    Returns:\n",
    "        autoencoder: The denoising autoencoder model.\n",
    "    \"\"\"\n",
    "    # Input layer\n",
    "    input_data = Input(shape=(input_dim,), name=\"input\")\n",
    "    \n",
    "    # Encoder\n",
    "    x = Dense(512, activation=\"relu\", name=\"encoder_dense_1\")(input_data)\n",
    "    x = BatchNormalization(name=\"encoder_bn_1\")(x)\n",
    "    x = Dropout(0.2, name=\"encoder_dropout_1\")(x)\n",
    "    \n",
    "    x = Dense(256, activation=\"relu\", name=\"encoder_dense_2\")(x)\n",
    "    x = BatchNormalization(name=\"encoder_bn_2\")(x)\n",
    "    x = Dropout(0.2, name=\"encoder_dropout_2\")(x)\n",
    "    \n",
    "    x = Dense(128, activation=\"relu\", name=\"encoder_dense_3\")(x)\n",
    "    x = BatchNormalization(name=\"encoder_bn_3\")(x)\n",
    "    x = Dropout(0.2, name=\"encoder_dropout_3\")(x)\n",
    "    \n",
    "    encoded = Dense(64, activation=\"relu\", name=\"encoder_latent\")(x)  # Latent space\n",
    "    \n",
    "    # Decoder\n",
    "    x = Dense(128, activation=\"relu\", name=\"decoder_dense_1\")(encoded)\n",
    "    x = BatchNormalization(name=\"decoder_bn_1\")(x)\n",
    "    x = Dropout(0.2, name=\"decoder_dropout_1\")(x)\n",
    "    \n",
    "    x = Dense(256, activation=\"relu\", name=\"decoder_dense_2\")(x)\n",
    "    x = BatchNormalization(name=\"decoder_bn_2\")(x)\n",
    "    x = Dropout(0.2, name=\"decoder_dropout_2\")(x)\n",
    "    \n",
    "    x = Dense(512, activation=\"relu\", name=\"decoder_dense_3\")(x)\n",
    "    x = BatchNormalization(name=\"decoder_bn_3\")(x)\n",
    "    x = Dropout(0.2, name=\"decoder_dropout_3\")(x)\n",
    "    \n",
    "    decoded = Dense(input_dim, activation=\"linear\", name=\"decoder_output\")(x)  # Reconstruct clean features\n",
    "    \n",
    "    # Autoencoder model\n",
    "    autoencoder = Model(input_data, decoded, name=\"DenoisingAutoencoder\")\n",
    "    \n",
    "    return autoencoder\n",
    "\n",
    "# Build the denoising autoencoder\n",
    "input_dim = 416  # Dimension of the input features\n",
    "autoencoder = build_denoising_autoencoder(input_dim)\n",
    "\n",
    "# Compile the autoencoder\n",
    "autoencoder.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "# Print the autoencoder summary\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f37566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8caa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_noise_list = []\n",
    "mae_denoise_list = []\n",
    "lp_values = []\n",
    "\n",
    "for x in range(5, 105, 10):\n",
    "    lp_values.append(x)\n",
    "\n",
    "    # Parameters\n",
    "    W = 1024\n",
    "    modulation_order = 16\n",
    "    C = W // 8\n",
    "    L = 13\n",
    "    Lp = x\n",
    "    noise_power = 0.1\n",
    "    B = 32\n",
    "\n",
    "    # Generate frequency-domain symbols\n",
    "    data = np.random.randint(0, modulation_order, W)\n",
    "    qam_symbols = (2 * (data % 4) - 3) + 1j * (2 * (data // 4) - 3)\n",
    "    qam_symbols /= np.sqrt(10)\n",
    "\n",
    "    time_domain_signal = np.fft.ifft(qam_symbols)\n",
    "\n",
    "    # Zero-mean Gaussian for amplitude\n",
    "    A_k = np.random.normal(loc=0.0, scale=1.0, size=Lp)\n",
    "    # Zero-mean Gaussian for phase\n",
    "    phi_k = np.random.normal(loc=0.0, scale=1.0, size=Lp)\n",
    "    p_bar = A_k * np.exp(1j * phi_k)\n",
    "    p_bar /= np.linalg.norm(p_bar)\n",
    "\n",
    "    perturbed_signal = np.convolve(p_bar, time_domain_signal, mode=\"full\")[:W]\n",
    "    cyclic_prefix = perturbed_signal[-C:]\n",
    "    transmit_signal = np.concatenate([cyclic_prefix, perturbed_signal])\n",
    "\n",
    "    csi_time_domain = csi_time_domain.reshape(20997, 32, 13)\n",
    "    num_csi_instances = csi_time_domain.shape[0]\n",
    "\n",
    "    y_real_all = np.zeros((num_csi_instances, B, W + C), dtype=complex)\n",
    "    H_pert_all = np.zeros((num_csi_instances, B, W), dtype=complex)\n",
    "\n",
    "    for i in range(num_csi_instances):\n",
    "        H_real = csi_time_domain[i]\n",
    "        for b in range(B):\n",
    "            y_real = convolve(H_real[b], transmit_signal, mode='full')[:W + C]\n",
    "            noise = np.sqrt(noise_power / 2) * (np.random.randn(W + C) + 1j * np.random.randn(W + C))\n",
    "            y_real_noisy = y_real + noise\n",
    "            y_real_no_cp = y_real_noisy[C:]\n",
    "\n",
    "            y_freq = np.fft.fft(y_real_no_cp)\n",
    "            s_freq = np.fft.fft(time_domain_signal)\n",
    "\n",
    "            H_pert_all[i, b, :] = y_freq / s_freq\n",
    "            H_pert_time = np.fft.ifft(H_pert_all[i, b, :])[:L]\n",
    "            csi_time_domain[i, b, :] = H_pert_time\n",
    "\n",
    "    csi_time_domain = csi_time_domain.reshape(20997, 4, 8, 13)\n",
    "    reshaped_csi = csi_time_domain.reshape(20997, 416)\n",
    "    X_train = reshaped_csi \n",
    "    y_train = reshaped_csi \n",
    "\n",
    "    history = autoencoder.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=30,\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        verbose=0\n",
    "    )\n",
    "    csi_tensor = tf.Variable(tf.convert_to_tensor(csi_time_domain, dtype=tf.complex64))\n",
    "    x_noise = model_layer([csi_tensor,csi_tensor])\n",
    "    csi_denoise = autoencoder.predict(reshaped_csi)\n",
    "    csi_denoise = csi_denoise.reshape(20997, 4, 8, 13)\n",
    "    csi_tensor_denoise = tf.Variable(tf.convert_to_tensor(csi_denoise, dtype=tf.complex64))\n",
    "    x_denoise = model_layer([csi_tensor_denoise, csi_tensor_denoise])\n",
    "    x_noise_transformed = affine_transform_channel_chart(groundtruth_positions, x_noise)\n",
    "    x_denoise_transformed = affine_transform_channel_chart(groundtruth_positions, x_denoise)\n",
    "    mae_noise = np.mean(np.abs(x_noise_transformed - groundtruth_positions))\n",
    "    mae_denosie = np.mean(np.abs(x_denoise_transformed - groundtruth_positions))\n",
    "\n",
    "    mae_noise_list.append(mae_noise)\n",
    "    mae_denoise_list.append(mae_denosie)\n",
    "\n",
    "# Plot MAE vs Perturbation Length\n",
    "plt.plot(lp_values, mae_noise_list, label='MAE (Noisy Features, Siamese)', marker='o')\n",
    "plt.plot(lp_values, mae_denoise_list, label='MAE (Denoised Features)', marker='s')\n",
    "plt.xlabel('Perturbation Length (Lp)')\n",
    "plt.ylabel('Mean Absolute Error (MAE)')\n",
    "plt.title('MAE vs Perturbation Length')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
