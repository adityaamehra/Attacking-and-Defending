{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd79ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors, kneighbors_graph\n",
    "from sklearn.manifold import trustworthiness\n",
    "from scipy.sparse.csgraph import dijkstra\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.manifold import MDS\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "from tqdm.auto import tqdm\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import queue\n",
    "import json\n",
    "\t\t\n",
    "[]\n",
    "# Antenna definitions\n",
    "ASSIGNMENTS = [\n",
    "\t[0, 13, 31, 29, 3, 7, 1, 12 ],\n",
    "\t[30, 26, 21, 25, 24, 8, 22, 15],\n",
    "\t[28, 5, 10, 14, 6, 2, 16, 18],\n",
    "\t[19, 4, 23, 17, 20, 11, 9, 27]\n",
    "]\n",
    "\n",
    "ANTENNACOUNT = np.sum([len(antennaArray) for antennaArray in ASSIGNMENTS])\n",
    "\n",
    "def load_calibrate_timedomain(path, offset_path):\n",
    "\toffsets = None\n",
    "\twith open(offset_path, \"r\") as offsetfile:\n",
    "\t\toffsets = json.load(offsetfile)\n",
    "\t\n",
    "\tdef record_parse_function(proto):\n",
    "\t\trecord = tf.io.parse_single_example(\n",
    "\t\t\tproto,\n",
    "\t\t\t{\n",
    "\t\t\t\t\"csi\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "\t\t\t\t\"pos-tachy\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "\t\t\t\t\"time\": tf.io.FixedLenFeature([], tf.float32, default_value=0),\n",
    "\t\t\t},\n",
    "\t\t)\n",
    "\n",
    "\t\tcsi = tf.ensure_shape(tf.io.parse_tensor(record[\"csi\"], out_type=tf.float32), (ANTENNACOUNT, 1024, 2))\n",
    "\t\tcsi = tf.complex(csi[:, :, 0], csi[:, :, 1])\n",
    "\t\tcsi = tf.signal.fftshift(csi, axes=1)\n",
    "\n",
    "\t\tposition = tf.ensure_shape(tf.io.parse_tensor(record[\"pos-tachy\"], out_type=tf.float64), (3))\n",
    "\t\ttime = tf.ensure_shape(record[\"time\"], ())\n",
    "\n",
    "\t\treturn csi, position[:2], time\n",
    "\n",
    "\tdef apply_calibration(csi, pos, time):\n",
    "\t\tsto_offset = tf.tensordot(tf.constant(offsets[\"sto\"]), 2 * np.pi * tf.range(tf.shape(csi)[1], dtype = np.float32) / tf.cast(tf.shape(csi)[1], np.float32), axes = 0) # symbol time offset\n",
    "\t\tcpo_offset = tf.tensordot(tf.constant(offsets[\"cpo\"]), tf.ones(tf.shape(csi)[1], dtype = np.float32), axes = 0) # carrier phase offset\n",
    "\t\tcsi = tf.multiply(csi, tf.exp(tf.complex(0.0, sto_offset + cpo_offset)))\n",
    "\n",
    "\t\treturn csi, pos, time\n",
    "\n",
    "\tdef csi_time_domain(csi, pos, time):\n",
    "\t\tcsi = tf.signal.fftshift(tf.signal.ifft(tf.signal.fftshift(csi, axes=1)),axes=1)\n",
    "\n",
    "\t\treturn csi, pos, time\n",
    "\n",
    "\tdef cut_out_taps(tap_start, tap_stop):\n",
    "\t\tdef cut_out_taps_func(csi, pos, time):\n",
    "\t\t\treturn csi[:,tap_start:tap_stop], pos, time\n",
    "\n",
    "\t\treturn cut_out_taps_func\n",
    "\n",
    "\tdef order_by_antenna_assignments(csi, pos, time):\n",
    "\t\tcsi = tf.stack([tf.gather(csi, antenna_inidces) for antenna_inidces in ASSIGNMENTS])\n",
    "\t\treturn csi, pos, time\n",
    "\t\n",
    "\tdataset = tf.data.TFRecordDataset(path)\n",
    "\t\n",
    "\tdataset = dataset.map(record_parse_function, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "\tdataset = dataset.map(apply_calibration, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "\tdataset = dataset.map(csi_time_domain, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "\tdataset = dataset.map(cut_out_taps(507, 520), num_parallel_calls = tf.data.AUTOTUNE)\n",
    "\tdataset = dataset.map(order_by_antenna_assignments, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "\n",
    "\treturn dataset\n",
    "\n",
    "inputpaths = [\n",
    "\t{\n",
    "\t\t\"tfrecords\" : \"dichasus/dichasus-cf02.tfrecords\",\n",
    "\t\t\"offsets\" : \"dichasus/reftx-offsets-dichasus-cf02.json\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"tfrecords\" : \"dichasus/dichasus-cf03.tfrecords\",\n",
    "\t\t\"offsets\" : \"dichasus/reftx-offsets-dichasus-cf03.json\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"tfrecords\" : \"dichasus/dichasus-cf04.tfrecords\",\n",
    "\t\t\"offsets\" : \"dichasus/reftx-offsets-dichasus-cf04.json\"\n",
    "\t}\n",
    "]\n",
    "\n",
    "full_dataset = load_calibrate_timedomain(inputpaths[0][\"tfrecords\"], inputpaths[0][\"offsets\"])\n",
    "\n",
    "for path in inputpaths[1:]:\n",
    "\tfull_dataset = full_dataset.concatenate(load_calibrate_timedomain(path[\"tfrecords\"], path[\"offsets\"]))\n",
    "    \n",
    "    \n",
    "\n",
    "def print_dataset_info(dataset, num_samples=5):\n",
    "    print(f\"Printing the first {num_samples} samples from the dataset:\")\n",
    "    for idx, (csi, position, time) in enumerate(dataset.take(num_samples)):\n",
    "        print(f\"\\nSample {idx + 1}:\")\n",
    "        print(\"-\" * 30)\n",
    "        print(f\"Position (x, y): {position.numpy()}\")\n",
    "        print(f\"Time: {time.numpy()}\")\n",
    "        print(f\"CSI Shape: {csi.shape}\")\n",
    "        print(f\"CSI (first antenna, first 10 subcarriers):\\n{csi[0, :10].numpy()}\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "# Call the function to print the dataset\n",
    "print_dataset_info(full_dataset, num_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ee6bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to the offsets file\n",
    "offset_path = inputpaths[0][\"offsets\"]\n",
    "\n",
    "# Load and print the offsets metadata\n",
    "with open(offset_path, \"r\") as offsetfile:\n",
    "    offsets = json.load(offsetfile)\n",
    "    print(\"Offsets Metadata:\", offsets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45493943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decimate dataset: Use only every 4th datapoint (to reduce number of points)\n",
    "training_set = full_dataset.enumerate().filter(lambda idx, value : (idx % 4 == 0))\n",
    "training_set = training_set.map(lambda idx, value : value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faed846",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"CSI shape: {csi.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaa729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Function to plot CSI data\n",
    "def plot_csi(csi, position, time, sample_idx=1):\n",
    "    # CSI for the first antenna group\n",
    "    csi_first_antenna = csi[0]  # Shape: (8, 13)\n",
    "\n",
    "    # Separate real and imaginary parts\n",
    "    real_values = np.real(csi_first_antenna)\n",
    "    imag_values = np.imag(csi_first_antenna)\n",
    "\n",
    "    # Plot real parts\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(f\"CSI Real Parts (Sample {sample_idx})\")\n",
    "    plt.xlabel(\"Subcarrier Index\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    for tap_idx in range(real_values.shape[0]):  # Loop over taps\n",
    "        plt.plot(real_values[tap_idx], label=f\"Tap {tap_idx+1}\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid()\n",
    "\n",
    "    # Plot imaginary parts\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(f\"CSI Imaginary Parts (Sample {sample_idx})\")\n",
    "    plt.xlabel(\"Subcarrier Index\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    for tap_idx in range(imag_values.shape[0]):  # Loop over taps\n",
    "        plt.plot(imag_values[tap_idx], label=f\"Tap {tap_idx+1}\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid()\n",
    "\n",
    "    # Overall title\n",
    "    plt.suptitle(f\"Position: {position.numpy()} | Time: {time.numpy()}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage with one sample\n",
    "for idx, (csi, position, time) in enumerate(full_dataset.take(1)):\n",
    "    plot_csi(csi.numpy(), position, time, sample_idx=idx + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021231d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Function to plot CSI data as real vs. imaginary\n",
    "def plot_csi_real_imag(csi, position, time, sample_idx=1):\n",
    "    # CSI for the first antenna group\n",
    "    csi_first_antenna = csi[0]  # Shape: (8, 13)\n",
    "    \n",
    "    # Plot real vs. imaginary for each tap\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    for tap_idx in range(csi_first_antenna.shape[0]):  # Loop over taps\n",
    "        real_values = np.real(csi_first_antenna[tap_idx])\n",
    "        imag_values = np.imag(csi_first_antenna[tap_idx])\n",
    "        plt.scatter(real_values, imag_values, label=f\"Tap {tap_idx + 1}\")\n",
    "    \n",
    "    # Plot configuration\n",
    "    plt.title(f\"CSI Real vs Imaginary (Sample {sample_idx})\")\n",
    "    plt.xlabel(\"Real Part\")\n",
    "    plt.ylabel(\"Imaginary Part\")\n",
    "    plt.axhline(0, color='gray', linestyle='--', linewidth=0.5)\n",
    "    plt.axvline(0, color='gray', linestyle='--', linewidth=0.5)\n",
    "    plt.grid()\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage with one sample\n",
    "for idx, (csi, position, time) in enumerate(full_dataset.take(1)):\n",
    "    plot_csi_real_imag(csi.numpy(), position, time, sample_idx=idx + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e6702c",
   "metadata": {},
   "outputs": [],
   "source": [
    "csi = tf.ensure_shape(tf.io.parse_tensor(record[\"csi\"], out_type=tf.float32), (ANTENNACOUNT, 1024, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107a4010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute and print the channel response\n",
    "def print_channel_response(csi, position, time, sample_idx=1):\n",
    "    # Compute magnitude and phase\n",
    "    csi_magnitude = np.abs(csi)  # Magnitude of the channel response\n",
    "    csi_phase = np.angle(csi)   # Phase of the channel response\n",
    "\n",
    "    print(f\"Sample {sample_idx}:\")\n",
    "    print(f\"Position (x, y): {position.numpy()}\")\n",
    "    print(f\"Time: {time.numpy()}\")\n",
    "\n",
    "    num_antennas = csi.shape[0]  # 4 antenna groups\n",
    "    num_taps = csi.shape[1]      # 8 taps\n",
    "    num_subcarriers = csi.shape[2]  # 13 subcarriers\n",
    "\n",
    "    for antenna_idx in range(num_antennas):\n",
    "        print(f\"\\nAntenna Group {antenna_idx + 1}:\")\n",
    "        for tap_idx in range(num_taps):\n",
    "            print(f\"  Tap {tap_idx + 1}:\")\n",
    "            print(f\"    Magnitude: {csi_magnitude[antenna_idx, tap_idx]}\")\n",
    "            print(f\"    Phase (radians): {csi_phase[antenna_idx, tap_idx]}\")\n",
    "\n",
    "# Example usage with one sample\n",
    "for idx, (csi, position, time) in enumerate(full_dataset.take(1)):\n",
    "    # Use CSI directly without reshaping\n",
    "    csi_matrix = csi.numpy()\n",
    "    print_channel_response(csi_matrix, position, time, sample_idx=idx + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fd10a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Inspect metadata in offsets file\n",
    "offset_path = inputpaths[0][\"offsets\"]\n",
    "with open(offset_path, \"r\") as offsetfile:\n",
    "    offsets = json.load(offsetfile)\n",
    "    print(\"Metadata from offsets file:\", offsets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07797094",
   "metadata": {},
   "outputs": [],
   "source": [
    "for csi, _, _ in full_dataset.take(1):\n",
    "    csi_magnitude = np.abs(csi.numpy())\n",
    "    print(\"Tap magnitudes per antenna:\", np.mean(csi_magnitude, axis=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b15abc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruth_positions = []\n",
    "csi_time_domain = []\n",
    "timestamps = []\n",
    "\n",
    "for csi, pos, time in training_set.batch(1000):\n",
    "\tcsi_time_domain.append(csi.numpy())\n",
    "\tgroundtruth_positions.append(pos.numpy())\n",
    "\ttimestamps.append(time.numpy())\n",
    "\n",
    "csi_time_domain = np.concatenate(csi_time_domain)\n",
    "groundtruth_positions = np.concatenate(groundtruth_positions)\n",
    "timestamps = np.concatenate(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb73882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_colorized(positions, groundtruth_positions, title = None, show = True, alpha = 1.0):\n",
    "\t# Generate RGB colors for datapoints\n",
    "\tcenter_point = np.zeros(2, dtype = np.float32)\n",
    "\tcenter_point[0] = 0.5 * (np.min(groundtruth_positions[:, 0], axis = 0) + np.max(groundtruth_positions[:, 0], axis = 0))\n",
    "\tcenter_point[1] = 0.5 * (np.min(groundtruth_positions[:, 1], axis = 0) + np.max(groundtruth_positions[:, 1], axis = 0))\n",
    "\tNormalizeData = lambda in_data : (in_data - np.min(in_data)) / (np.max(in_data) - np.min(in_data))\n",
    "\trgb_values = np.zeros((groundtruth_positions.shape[0], 3))\n",
    "\trgb_values[:, 0] = 1 - 0.9 * NormalizeData(groundtruth_positions[:, 0])\n",
    "\trgb_values[:, 1] = 0.8 * NormalizeData(np.square(np.linalg.norm(groundtruth_positions - center_point, axis=1)))\n",
    "\trgb_values[:, 2] = 0.9 * NormalizeData(groundtruth_positions[:, 1])\n",
    "\n",
    "\t# Plot datapoints\n",
    "\tplt.figure(figsize=(6, 6))\n",
    "\tif title is not None:\n",
    "\t\tplt.title(title, fontsize=16)\n",
    "\tplt.scatter(positions[:, 0], positions[:, 1], c = rgb_values, alpha = alpha, s = 10, linewidths = 0)\n",
    "\tplt.xlabel(\"x coordinate\")\n",
    "\tplt.ylabel(\"y coordinate\")\n",
    "\tif show: plt.savefig('plt1.png')\n",
    "\n",
    "plot_colorized(groundtruth_positions, groundtruth_positions, title=\"Ground Truth Positions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98591183",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('plt1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89ffb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def compute_adp_dissimilarity_matrix(csi_array):\n",
    "\toutput = tf.TensorArray(tf.float32, size = csi_array.shape[0])\n",
    "\n",
    "\tpowers = tf.einsum(\"lbmt,lbmt->lbt\", csi_array, tf.math.conj(csi_array))\n",
    "\tfor i in tf.range(csi_array.shape[0]):\n",
    "\t\tw = csi_array[i:,:,:,:]\n",
    "\t\th = csi_array[i,:,:,:]\n",
    "\n",
    "\t\tdotproducts = tf.abs(tf.square(tf.einsum(\"bmt,lbmt->lbt\", tf.math.conj(h), w)))\n",
    "\t\td_new = tf.math.reduce_sum(1 - dotproducts / tf.math.real(powers[i] * powers[i:]), axis = (1, 2))\n",
    "\t\td = tf.concat([tf.zeros(i), tf.maximum(d_new, 0)], 0)\n",
    "\n",
    "\t\toutput = output.write(i, d)\n",
    "\n",
    "\tdissim_upper_tri = output.stack()\n",
    "\treturn dissim_upper_tri + tf.transpose(dissim_upper_tri)\n",
    "\n",
    "adp_dissimilarity_matrix = compute_adp_dissimilarity_matrix(csi_time_domain).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad7802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute timestamp-based dissimilarity matrix\n",
    "timestamp_dissimilarity_matrix = np.abs(np.subtract.outer(timestamps, timestamps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8cb4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_THRESHOLD = 2\n",
    "small_time_dissimilarity_indices = np.logical_and(timestamp_dissimilarity_matrix < TIME_THRESHOLD, timestamp_dissimilarity_matrix > 0)\n",
    "small_time_dissimilarities = timestamp_dissimilarity_matrix[small_time_dissimilarity_indices]\n",
    "small_adp_dissimilarities = adp_dissimilarity_matrix[small_time_dissimilarity_indices]\n",
    "\n",
    "n_bins = 1500\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "occurences, edges, patches = ax1.hist(small_adp_dissimilarities / small_time_dissimilarities, range = (0, 50), bins = n_bins)\n",
    "ax1.set_xlabel(\"$D_\\mathrm{APDP} / D_\\mathrm{time}$\")\n",
    "ax1.set_ylabel(\"Number of Occurences\")\n",
    "plt.savefig('plt2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aa3e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_centers = edges[:-1] + np.diff(edges) / 2.\n",
    "max_bin = np.argmax(occurences)\n",
    "\n",
    "if max_bin > 0:\n",
    "    min_threshold = np.quantile(occurences[:max_bin], 0.5)\n",
    "\n",
    "    for threshold_bin in range(max_bin - 1, -1, -1):\n",
    "        if occurences[threshold_bin] < min_threshold:\n",
    "            break\n",
    "\n",
    "    scaling_factor = bin_centers[threshold_bin]\n",
    "\n",
    "    plt.bar(bin_centers[:max_bin], occurences[:max_bin], width=edges[1] - edges[0])\n",
    "    plt.axhline(y=min_threshold, color='r', linestyle='-')\n",
    "    plt.text(4, min_threshold + 10, \"Mode Separation Threshold\", color='r',)\n",
    "    plt.axvline(x=scaling_factor, color='r', linestyle='-')\n",
    "    plt.xlabel(\"$D_\\mathrm{APDP} / D_\\mathrm{time}$\")\n",
    "    plt.ylabel(\"Number of Occurrences\")\n",
    "    plt.savefig('plt3.png')\n",
    "\n",
    "    print(\"gamma =\", scaling_factor)\n",
    "else:\n",
    "    print(\"No occurrences to plot.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0d7845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuse ADP-based and time-based dissimilarity matrices\n",
    "dissimilarity_matrix_fused = np.minimum(adp_dissimilarity_matrix, timestamp_dissimilarity_matrix * scaling_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d36d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 20\n",
    "\n",
    "nbrs_alg = NearestNeighbors(n_neighbors = n_neighbors, metric=\"precomputed\", n_jobs = -1)\n",
    "nbrs = nbrs_alg.fit(dissimilarity_matrix_fused)\n",
    "nbg = kneighbors_graph(nbrs, n_neighbors, metric = \"precomputed\", mode=\"distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7900732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocess as mpp \n",
    "\n",
    "def shortest_path_worker(todo_queue, output_queue):\n",
    "\twhile True:\n",
    "\t\tindex = todo_queue.get()\n",
    "\n",
    "\t\tif index == -1:\n",
    "\t\t\toutput_queue.put((-1, None))\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\td = dijkstra(nbg, directed=False, indices=index)\n",
    "\t\toutput_queue.put((index, d))\n",
    "\n",
    "\n",
    "dissimilarity_matrix_geodesic = np.zeros((nbg.shape[0], nbg.shape[1]), dtype = np.float32)\n",
    "\n",
    "with tqdm(total = nbg.shape[0]**2) as pbar:\n",
    "\ttodo_queue = mpp.Queue()\n",
    "\toutput_queue = mpp.Queue()\n",
    "\n",
    "\tfor i in range(nbg.shape[0]):\n",
    "\t\ttodo_queue.put(i)\n",
    "\t\n",
    "\tfor i in range(mp.cpu_count()):\n",
    "\t\ttodo_queue.put(-1)\n",
    "\t\tp = mpp.Process(target = shortest_path_worker, args = (todo_queue, output_queue))\n",
    "\t\tp.start()\n",
    "\n",
    "\tfinished_processes = 0\n",
    "\twhile finished_processes != mpp.cpu_count():\n",
    "\t\ti, d = output_queue.get()\n",
    "\n",
    "\t\tif i == -1:\n",
    "\t\t\tfinished_processes = finished_processes + 1\n",
    "\t\telse:\n",
    "\t\t\tdissimilarity_matrix_geodesic[i,:] = d\n",
    "\t\t\tpbar.update(len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9fca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute distances between groundtruth positions\n",
    "groundtruth_distance_matrix = distance_matrix(groundtruth_positions, groundtruth_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33560a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dissimilarity_over_euclidean_distance(dissimilarity_matrix, distance_matrix, label = None):\n",
    "\tnth_reduction = 10\n",
    "\tdissimilarities_flat = dissimilarity_matrix[::nth_reduction, ::nth_reduction].flatten()\n",
    "\tdistances_flat = distance_matrix[::nth_reduction, ::nth_reduction].flatten()\n",
    "\t\n",
    "\tmax_distance = np.max(distances_flat)\n",
    "\tbins = np.linspace(0, max_distance, 200)\n",
    "\tbin_indices = np.digitize(distances_flat, bins)\n",
    "\t\n",
    "\tbin_medians = np.zeros(len(bins) - 1)\n",
    "\tbin_25_perc = np.zeros(len(bins) - 1)\n",
    "\tbin_75_perc = np.zeros(len(bins) - 1)\n",
    "\tfor i in range(1, len(bins)):\n",
    "\t\tbin_values = dissimilarities_flat[bin_indices == i]\n",
    "\t\tbin_25_perc[i - 1], bin_medians[i - 1], bin_75_perc[i - 1] = np.percentile(bin_values, [25, 50, 75])\n",
    "\t\n",
    "\tplt.plot(bins[:-1], bin_medians, label = label)\n",
    "\tplt.fill_between(bins[:-1], bin_25_perc, bin_75_perc, alpha=0.5)\n",
    "\t\t\n",
    "plt.figure(figsize=(8,4))\n",
    "\n",
    "plot_dissimilarity_over_euclidean_distance(dissimilarity_matrix_geodesic, groundtruth_distance_matrix, \"G-fuse\")\n",
    "plot_dissimilarity_over_euclidean_distance(scaling_factor * adp_dissimilarity_matrix, groundtruth_distance_matrix, \"ADP\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Euclidean Distance [m]\")\n",
    "plt.ylabel(\"Scaled Dissimilarity\")\n",
    "plt.savefig('plt3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9086f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import MDS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nth_reduction = 10\n",
    "\n",
    "# Assuming dissimilarity_matrix_geodesic is defined\n",
    "reduced_dissimilarity_matrix_geodesic = dissimilarity_matrix_geodesic[::nth_reduction, ::nth_reduction]\n",
    "\n",
    "# Check for infinity or large values\n",
    "if np.any(np.isinf(reduced_dissimilarity_matrix_geodesic)) or np.max(reduced_dissimilarity_matrix_geodesic) > 1e6:\n",
    "    # Handle infinity or large values\n",
    "    reduced_dissimilarity_matrix_geodesic[np.isinf(reduced_dissimilarity_matrix_geodesic)] = 0  # Replace infinity with 0\n",
    "    reduced_dissimilarity_matrix_geodesic[reduced_dissimilarity_matrix_geodesic > 1e6] = 1e6  # Clip large values to 1e6\n",
    "\n",
    "embedding_isomap = MDS(metric=True, dissimilarity='precomputed', max_iter=80, normalized_stress=False)\n",
    "proj_isomap = embedding_isomap.fit_transform(reduced_dissimilarity_matrix_geodesic)\n",
    "\n",
    "# Assuming groundtruth_positions is defined\n",
    "plot_colorized(proj_isomap, groundtruth_positions[::nth_reduction], title=\"Isomap Channel Chart\")\n",
    "plt.savefig('plt4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce85f940",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineeringLayer(tf.keras.layers.Layer):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(FeatureEngineeringLayer, self).__init__(dtype = tf.complex64)\n",
    "\n",
    "\tdef call(self, csi):\n",
    "\t\t# Compute sample correlations for any combination of two antennas in the whole system\n",
    "\t\t# for the same datapoint and time tap.\n",
    "\t\tsample_autocorrelations = tf.einsum(\"damt,dbnt->dtabmn\", csi, tf.math.conj(csi))\n",
    "\t\treturn tf.stack([tf.math.real(sample_autocorrelations), tf.math.imag(sample_autocorrelations)], axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7721b3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_count = np.shape(csi_time_domain)[1]\n",
    "antenna_per_array_count = np.shape(csi_time_domain)[2]\n",
    "tap_count = np.shape(csi_time_domain)[3]\n",
    "\n",
    "cc_embmodel_input = tf.keras.Input(shape=(array_count, antenna_per_array_count, tap_count), name=\"input\", dtype = tf.complex64)\n",
    "cc_embmodel_output = FeatureEngineeringLayer()(cc_embmodel_input)\n",
    "cc_embmodel_output = tf.keras.layers.Flatten()(cc_embmodel_output)\n",
    "cc_embmodel_output = tf.keras.layers.Dense(1024, activation = \"relu\")(cc_embmodel_output)\n",
    "cc_embmodel_output = tf.keras.layers.BatchNormalization()(cc_embmodel_output)\n",
    "cc_embmodel_output = tf.keras.layers.Dense(512, activation = \"relu\")(cc_embmodel_output)\n",
    "cc_embmodel_output = tf.keras.layers.BatchNormalization()(cc_embmodel_output)\n",
    "cc_embmodel_output = tf.keras.layers.Dense(256, activation = \"relu\")(cc_embmodel_output)\n",
    "cc_embmodel_output = tf.keras.layers.BatchNormalization()(cc_embmodel_output)\n",
    "cc_embmodel_output = tf.keras.layers.Dense(128, activation = \"relu\")(cc_embmodel_output)\n",
    "cc_embmodel_output = tf.keras.layers.BatchNormalization()(cc_embmodel_output)\n",
    "cc_embmodel_output = tf.keras.layers.Dense(64, activation = \"relu\")(cc_embmodel_output)\n",
    "cc_embmodel_output = tf.keras.layers.BatchNormalization()(cc_embmodel_output)\n",
    "cc_embmodel_output = tf.keras.layers.Dense(2, activation = \"linear\")(cc_embmodel_output)\n",
    "\n",
    "cc_embmodel = tf.keras.Model(inputs=cc_embmodel_input, outputs=cc_embmodel_output, name = \"ForwardChartingFunction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7704b088",
   "metadata": {},
   "outputs": [],
   "source": [
    "dissimilarity_margin = np.quantile(dissimilarity_matrix_geodesic, 0.01)\n",
    "\n",
    "def siamese_loss(y_true, y_pred):\n",
    "    y_true = y_true[:,0]\n",
    "    pos_A, pos_B = (y_pred[:,:2], y_pred[:,2:])\n",
    "    distances_pred = tf.math.reduce_euclidean_norm(pos_A - pos_B, axis = 1)\n",
    "\n",
    "    return tf.reduce_mean(tf.square(distances_pred - y_true) / (y_true + dissimilarity_margin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ee2f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = tf.keras.layers.Input(shape = (array_count, antenna_per_array_count, tap_count,), dtype = tf.complex64)\n",
    "input_B = tf.keras.layers.Input(shape = (array_count, antenna_per_array_count, tap_count,), dtype = tf.complex64)\n",
    "\n",
    "embedding_A = cc_embmodel(input_A)\n",
    "embedding_B = cc_embmodel(input_B)\n",
    "\n",
    "output = tf.keras.layers.concatenate([embedding_A, embedding_B], axis=1)\n",
    "model = tf.keras.models.Model([input_A, input_B], output, name = \"SiameseNeuralNetwork\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b9f812",
   "metadata": {},
   "outputs": [],
   "source": [
    "csi_time_domain_tensor = tf.constant(csi_time_domain)\n",
    "dissimilarity_matrix_geodesic_tensor = tf.constant(dissimilarity_matrix_geodesic)\n",
    "\n",
    "datapoint_count = tf.shape(csi_time_domain_tensor)[0].numpy()\n",
    "\n",
    "random_integer_pairs_dataset = tf.data.Dataset.zip(tf.data.Dataset.random(), tf.data.Dataset.random())\n",
    "\n",
    "@tf.function\n",
    "def fill_pairs(randA, randB):\n",
    "    return (csi_time_domain_tensor[randA % datapoint_count], csi_time_domain_tensor[randB % datapoint_count]), dissimilarity_matrix_geodesic_tensor[randA % datapoint_count, randB % datapoint_count]\n",
    "\n",
    "random_pair_dataset = random_integer_pairs_dataset.map(fill_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04445fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(loss = siamese_loss, optimizer = optimizer)\n",
    "\n",
    "samples_per_session = 150000\n",
    "learning_rates = [1e-2, 1e-2, 8e-3, 4e-3, 1e-3, 5e-4, 2e-4, 1e-4]\n",
    "batch_size = [500, 1000, 1500, 2000, 3000, 4000, 5000, 6000]\n",
    "\n",
    "for l in range(len(learning_rates)):\n",
    "    print(\"\\nTraining Session \", l + 1, \"\\nBatch Size: \", batch_size[l], \"\\nLearning rate: \", learning_rates[l])\n",
    "\n",
    "    # Fit model\n",
    "    optimizer.learning_rate.assign(learning_rates[l])\n",
    "    model.fit(random_pair_dataset.batch(batch_size[l]).prefetch(tf.data.AUTOTUNE), steps_per_epoch = samples_per_session // batch_size[l])\n",
    "\n",
    "    # Plot Channel Chart\n",
    "    print(\"Running inference to plot channel chart\")\n",
    "    channel_chart_positions = cc_embmodel.predict(csi_time_domain)\n",
    "    plot_colorized(channel_chart_positions, groundtruth_positions, title = \"Siamese-Based Channel Chart - Session \" + str(l + 1))\n",
    "    plt.savefig('channel_chart_session_' + str(l + 1) + '.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dccc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "csi_time_domain_tensor = tf.constant(csi_time_domain)\n",
    "dissimilarity_matrix_geodesic_tensor = tf.constant(dissimilarity_matrix_geodesic)\n",
    "\n",
    "datapoint_count = tf.shape(csi_time_domain_tensor)[0].numpy()\n",
    "\n",
    "random_integer_pairs_dataset = tf.data.Dataset.zip(tf.data.Dataset.random(), tf.data.Dataset.random())\n",
    "\n",
    "@tf.function\n",
    "def fill_pairs(randA, randB):\n",
    "    return (csi_time_domain_tensor[randA % datapoint_count], csi_time_domain_tensor[randB % datapoint_count]), dissimilarity_matrix_geodesic_tensor[randA % datapoint_count, randB % datapoint_count]\n",
    "\n",
    "random_pair_dataset = random_integer_pairs_dataset.map(fill_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d10261",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_chart_positions = cc_embmodel.predict(csi_time_domain)\n",
    "\n",
    "def affine_transform_channel_chart(groundtruth_pos, channel_chart_pos):\n",
    "    pad = lambda x: np.hstack([x, np.ones((x.shape[0], 1))])\n",
    "    unpad = lambda x: x[:,:-1]\n",
    "    A, res, rank, s = np.linalg.lstsq(pad(channel_chart_pos), pad(groundtruth_pos), rcond = None)\n",
    "    transform = lambda x: unpad(np.dot(pad(x), A))\n",
    "    return transform(channel_chart_pos)\n",
    "\n",
    "channel_chart_positions_transformed = affine_transform_channel_chart(groundtruth_positions, channel_chart_positions)\n",
    "plot_colorized(groundtruth_positions, groundtruth_positions, title = \"Ground Truth Positions\")\n",
    "plt.savefig('plt5.png')\n",
    "plot_colorized(channel_chart_positions_transformed, groundtruth_positions, title = \"Channel Chart After Affine Transform\")\n",
    "plt.savefig('plt6.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e085998e",
   "metadata": {},
   "outputs": [],
   "source": [
    "errorvectors = groundtruth_positions - channel_chart_positions_transformed\n",
    "errors = np.sqrt(errorvectors[:,0]**2 + errorvectors[:,1]**2)\n",
    "mae = np.mean(errors)\n",
    "\n",
    "nth_errorvector = 15\n",
    "plot_colorized(channel_chart_positions_transformed, groundtruth_positions, title = \"Error Vectors, MAE = \" + str(mae) + \"m\", show = False, alpha = 0.3)\n",
    "plt.quiver(channel_chart_positions_transformed[::nth_errorvector, 0], channel_chart_positions_transformed[::nth_errorvector, 1], errorvectors[::nth_errorvector, 0], errorvectors[::nth_errorvector, 1], color = \"black\", angles = \"xy\", scale_units = \"xy\", scale = 1)\n",
    "plt.savefig('plt7.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2460a66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count, bins_count = np.histogram(errors, bins=200)\n",
    "pdf = count / sum(count)\n",
    "cdf = np.cumsum(pdf)\n",
    "\n",
    "bins_count[0] = 0\n",
    "cdf = np.append([0], cdf)\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.plot(bins_count, cdf)\n",
    "plt.xlim((0, 2))\n",
    "plt.xlabel(\"Absolute Localization Error [m]\")\n",
    "plt.ylabel(\"CDF\")\n",
    "plt.grid()\n",
    "plt.savefig('plt8.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4007992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuity is identical to trustworthiness, except that original space and embedding space are swapped\n",
    "def continuity(*args, **kwargs):\n",
    "\targs = list(args)\n",
    "\targs[0], args[1] = args[1], args[0]\n",
    "\treturn trustworthiness(*args, **kwargs)\n",
    "\n",
    "def kruskal_stress(X, X_embedded):\n",
    "\tdist_X = distance_matrix(X, X)\n",
    "\tdist_X_embedded = distance_matrix(X_embedded, X_embedded)\n",
    "\tbeta = np.divide(np.sum(dist_X * dist_X_embedded), np.sum(dist_X_embedded * dist_X_embedded))\n",
    "\n",
    "\treturn np.sqrt(np.divide(np.sum(np.square((dist_X - beta * dist_X_embedded))), np.sum(dist_X * dist_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b91ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate CT / TW / KS on a subset of the whole dataset\n",
    "subset_indices = random.sample(range(len(groundtruth_positions)), len(groundtruth_positions) // 5)\n",
    "groundtruth_positions_subset = groundtruth_positions[subset_indices]\n",
    "channel_chart_positions_subset = channel_chart_positions[subset_indices]\n",
    "\n",
    "ct = continuity(groundtruth_positions_subset, channel_chart_positions_subset, n_neighbors = int(0.05 * len(groundtruth_positions_subset)))\n",
    "tw = trustworthiness(groundtruth_positions_subset, channel_chart_positions_subset, n_neighbors = int(0.05 * len(groundtruth_positions_subset)))\n",
    "ks = kruskal_stress(groundtruth_positions_subset, channel_chart_positions_subset)\n",
    "\n",
    "print(\"CT: {} \\nTW: {} \\nKS: {}\".format(*np.around((ct, tw, ks), 5)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Summer_Intern",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
